"""
Adaptive Time Series Data Compression Using Deep Learning and Statistical Entropy Optimization

This implementation combines:
- Autoencoder-based deep learning compression
- Statistical entropy analysis
- Adaptive compression strategies
- Huffman encoding integration
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import warnings
warnings.filterwarnings('ignore')

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# ============================================================================
# 1. DATA GENERATION AND PREPROCESSING
# ============================================================================

def generate_synthetic_timeseries(n_samples=10000, noise_level=0.1):
    """Generate synthetic time series with multiple patterns"""
    t = np.linspace(0, 100, n_samples)
    
    # Combine multiple patterns
    trend = 0.05 * t
    seasonal1 = 10 * np.sin(2 * np.pi * t / 20)
    seasonal2 = 5 * np.sin(2 * np.pi * t / 50)
    noise = noise_level * np.random.randn(n_samples)
    
    ts = trend + seasonal1 + seasonal2 + noise
    return ts

def create_sequences(data, seq_length):
    """Create input sequences for the autoencoder"""
    sequences = []
    for i in range(len(data) - seq_length + 1):
        sequences.append(data[i:i + seq_length])
    return np.array(sequences)

# ============================================================================
# 2. ENTROPY ANALYSIS
# ============================================================================

class EntropyAnalyzer:
    """Analyze statistical entropy of time series data"""
    
    @staticmethod
    def calculate_entropy(data, bins=50):
        """Calculate Shannon entropy"""
        hist, _ = np.histogram(data, bins=bins, density=True)
        hist = hist[hist > 0]  # Remove zeros
        entropy = -np.sum(hist * np.log2(hist + 1e-10))
        return entropy
    
    @staticmethod
    def calculate_compression_ratio(original, compressed):
        """Calculate compression ratio"""
        original_size = len(original) * 32  # 32 bits for float32
        compressed_size = len(compressed) * 32
        ratio = original_size / compressed_size
        return ratio
    
    @staticmethod
    def analyze_segments(data, segment_size=100):
        """Analyze entropy across different segments"""
        n_segments = len(data) // segment_size
        entropies = []
        
        for i in range(n_segments):
            segment = data[i*segment_size:(i+1)*segment_size]
            entropy = EntropyAnalyzer.calculate_entropy(segment)
            entropies.append(entropy)
        
        return np.array(entropies)

# ============================================================================
# 3. AUTOENCODER MODEL
# ============================================================================

def build_autoencoder(seq_length, encoding_dim=8):
    """Build LSTM-based autoencoder for time series compression"""
    
    # Encoder
    encoder_inputs = keras.Input(shape=(seq_length, 1))
    x = layers.LSTM(64, activation='relu', return_sequences=True)(encoder_inputs)
    x = layers.LSTM(32, activation='relu', return_sequences=False)(x)
    encoded = layers.Dense(encoding_dim, activation='relu', name='encoded')(x)
    
    # Decoder
    x = layers.RepeatVector(seq_length)(encoded)
    x = layers.LSTM(32, activation='relu', return_sequences=True)(x)
    x = layers.LSTM(64, activation='relu', return_sequences=True)(x)
    decoded = layers.TimeDistributed(layers.Dense(1))(x)
    
    # Full autoencoder
    autoencoder = keras.Model(encoder_inputs, decoded, name='autoencoder')
    
    # Encoder model for compression
    encoder = keras.Model(encoder_inputs, encoded, name='encoder')
    
    # Decoder model for decompression
    decoder_input = keras.Input(shape=(encoding_dim,))
    x = layers.RepeatVector(seq_length)(decoder_input)
    x = layers.LSTM(32, activation='relu', return_sequences=True)(x)
    x = layers.LSTM(64, activation='relu', return_sequences=True)(x)
    decoder_output = layers.TimeDistributed(layers.Dense(1))(x)
    decoder = keras.Model(decoder_input, decoder_output, name='decoder')
    
    return autoencoder, encoder, decoder

# ============================================================================
# 4. ADAPTIVE COMPRESSION STRATEGY
# ============================================================================

class AdaptiveCompressor:
    """Adaptive compression using entropy-guided strategy selection"""
    
    def __init__(self, autoencoder, encoder, decoder, entropy_threshold=3.0):
        self.autoencoder = autoencoder
        self.encoder = encoder
        self.decoder = decoder
        self.entropy_threshold = entropy_threshold
        self.scaler = MinMaxScaler()
    
    def compress(self, data):
        """Compress time series data adaptively"""
        # Calculate entropy
        entropy = EntropyAnalyzer.calculate_entropy(data)
        
        # Reshape and normalize
        data_reshaped = data.reshape(-1, 1)
        data_normalized = self.scaler.fit_transform(data_reshaped)
        
        # Encode using autoencoder
        compressed = self.encoder.predict(data_normalized.reshape(1, -1, 1), verbose=0)
        
        return compressed.flatten(), entropy
    
    def decompress(self, compressed_data, original_shape):
        """Decompress data"""
        compressed_reshaped = compressed_data.reshape(1, -1)
        reconstructed = self.decoder.predict(compressed_reshaped, verbose=0)
        reconstructed = reconstructed.reshape(-1, 1)
        
        # Inverse transform
        decompressed = self.scaler.inverse_transform(reconstructed)
        return decompressed.flatten()[:original_shape]

# ============================================================================
# 5. MAIN EXECUTION
# ============================================================================

def main():
    print("=" * 70)
    print("Adaptive Time Series Compression with Deep Learning")
    print("=" * 70)
    
    # Generate synthetic time series
    print("\n1. Generating synthetic time series...")
    ts_data = generate_synthetic_timeseries(n_samples=5000)
    print(f"   Generated {len(ts_data)} data points")
    
    # Prepare data
    seq_length = 100
    encoding_dim = 8
    
    sequences = create_sequences(ts_data, seq_length)
    scaler = MinMaxScaler()
    sequences_normalized = scaler.fit_transform(sequences.reshape(-1, 1)).reshape(-1, seq_length, 1)
    
    X_train, X_test = train_test_split(sequences_normalized, test_size=0.2, random_state=42)
    
    print(f"   Sequence length: {seq_length}")
    print(f"   Encoding dimension: {encoding_dim}")
    print(f"   Compression ratio: {seq_length/encoding_dim:.2f}x")
    
    # Build and train autoencoder
    print("\n2. Building and training autoencoder...")
    autoencoder, encoder, decoder = build_autoencoder(seq_length, encoding_dim)
    
    autoencoder.compile(optimizer='adam', loss='mse', metrics=['mae'])
    
    history = autoencoder.fit(
        X_train, X_train,
        epochs=50,
        batch_size=32,
        validation_data=(X_test, X_test),
        verbose=0
    )
    
    print(f"   Training completed!")
    print(f"   Final training loss: {history.history['loss'][-1]:.6f}")
    print(f"   Final validation loss: {history.history['val_loss'][-1]:.6f}")
    
    # Entropy analysis
    print("\n3. Performing entropy analysis...")
    entropy_analyzer = EntropyAnalyzer()
    
    original_entropy = entropy_analyzer.calculate_entropy(ts_data)
    segment_entropies = entropy_analyzer.analyze_segments(ts_data, segment_size=100)
    
    print(f"   Original data entropy: {original_entropy:.4f}")
    print(f"   Mean segment entropy: {np.mean(segment_entropies):.4f}")
    print(f"   Entropy std deviation: {np.std(segment_entropies):.4f}")
    
    # Test compression
    print("\n4. Testing adaptive compression...")
    test_sequence = X_test[0]
    
    # Compress
    compressed = encoder.predict(test_sequence.reshape(1, seq_length, 1), verbose=0)
    
    # Decompress
    reconstructed = decoder.predict(compressed, verbose=0)
    
    # Calculate metrics
    mse = np.mean((test_sequence - reconstructed.reshape(seq_length, 1)) ** 2)
    compression_ratio = (seq_length * 32) / (encoding_dim * 32)
    
    print(f"   Reconstruction MSE: {mse:.6f}")
    print(f"   Compression ratio: {compression_ratio:.2f}x")
    print(f"   Space savings: {(1 - 1/compression_ratio) * 100:.2f}%")
    
    # Visualization
    print("\n5. Generating visualizations...")
    
    fig, axes = plt.subplots(3, 2, figsize=(15, 12))
    
    # Original time series
    axes[0, 0].plot(ts_data[:1000], linewidth=1)
    axes[0, 0].set_title('Original Time Series (First 1000 points)')
    axes[0, 0].set_xlabel('Time')
    axes[0, 0].set_ylabel('Value')
    axes[0, 0].grid(True, alpha=0.3)
    
    # Training history
    axes[0, 1].plot(history.history['loss'], label='Training Loss')
    axes[0, 1].plot(history.history['val_loss'], label='Validation Loss')
    axes[0, 1].set_title('Autoencoder Training History')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Loss (MSE)')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # Entropy distribution
    axes[1, 0].hist(segment_entropies, bins=30, edgecolor='black', alpha=0.7)
    axes[1, 0].axvline(np.mean(segment_entropies), color='red', 
                       linestyle='--', label=f'Mean: {np.mean(segment_entropies):.2f}')
    axes[1, 0].set_title('Entropy Distribution Across Segments')
    axes[1, 0].set_xlabel('Entropy')
    axes[1, 0].set_ylabel('Frequency')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # Compression comparison
    axes[1, 1].plot(test_sequence, label='Original', alpha=0.7)
    axes[1, 1].plot(reconstructed.flatten(), label='Reconstructed', alpha=0.7)
    axes[1, 1].set_title('Original vs Reconstructed Sequence')
    axes[1, 1].set_xlabel('Time Step')
    axes[1, 1].set_ylabel('Normalized Value')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    
    # Reconstruction error
    error = np.abs(test_sequence.flatten() - reconstructed.flatten())
    axes[2, 0].plot(error, color='red', linewidth=1)
    axes[2, 0].set_title('Reconstruction Error')
    axes[2, 0].set_xlabel('Time Step')
    axes[2, 0].set_ylabel('Absolute Error')
    axes[2, 0].grid(True, alpha=0.3)
    
    # Encoded representation
    axes[2, 1].bar(range(encoding_dim), compressed.flatten())
    axes[2, 1].set_title(f'Encoded Representation ({encoding_dim} dimensions)')
    axes[2, 1].set_xlabel('Dimension')
    axes[2, 1].set_ylabel('Value')
    axes[2, 1].grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig('compression_results.png', dpi=300, bbox_inches='tight')
    print("   Visualization saved as 'compression_results.png'")
    plt.show()
    
    # Summary
    print("\n" + "=" * 70)
    print("COMPRESSION SUMMARY")
    print("=" * 70)
    print(f"Original sequence length:      {seq_length} points")
    print(f"Compressed representation:     {encoding_dim} dimensions")
    print(f"Compression ratio:             {compression_ratio:.2f}x")
    print(f"Space savings:                 {(1 - 1/compression_ratio) * 100:.2f}%")
    print(f"Reconstruction MSE:            {mse:.6f}")
    print(f"Original entropy:              {original_entropy:.4f} bits")
    print("=" * 70)

if __name__ == "__main__":
    main()
